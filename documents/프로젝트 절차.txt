1.1 기본 폴더 구조 구성

1.2 개발 환경 설정
- 백엔드: Python 
- 프론트엔드: HTML5, CSS3, JavaScript (반응형)
- 데이터베이스: PostgreSQL
- 크롤링: Python (BeautifulSoup, Scrapy)
- AI 요약: OpenAI API
- 도커사용
- 모듈별 분리: 사용자/관리자, 백앤드, 크롤링/AI 총 4개로 각 모듈로 분리
 * 사용자 및 관리자: 웹 프론트엔드 (React 기반)
 * Java Spring Boot 기반 메인 API 서버
 * 크롤링 + AI 분석 통합 Python 서비스 (FastAPI 기반)


2.1 주요 테이블 생성
- news (뉴스 기본 정보)
- news_summary (AI 요약 정보)
- fact_check_match (팩트체크 매칭)
- user_votes (사용자 투표)
- user_comments (사용자 댓글)
- trending_keywords (트렌딩 키워드)
- users (사용자 정보)
- categories (뉴스 카테고리)

2.2 데이터 관계 설정
- 외래키 관계 정의
- 인덱스 최적화

## 3. 크롤링 시스템 구현 

### 3.1 뉴스 크롤링 모듈 
- **RSS 피드 수집 구현**
  - 네이버 뉴스 RSS 크롤러 (`/crawler-service/crawlers/naver_crawler.py`)
  - 다음 뉴스 RSS 크롤러 (`/crawler-service/crawlers/daum_crawler.py`)
- **스케줄링: 06시~24시, 3시간 간격** 
  - 스케줄러 구현 (`/crawler-service/schedulers/crawler_scheduler.py`)
- **중복 제거 로직**
  - URL 및 컨텐츠 해시 기반 중복 확인
- **카테고리별 분류 (정치, 경제, 사회, 국제, IT/과학, 연예)**
  - 카테고리 매핑 및 데이터베이스 연동

### 3.2 트렌딩 키워드 수집 
- **네이버 실시간 이슈 수집**
  - 트렌딩 키워드 크롤러 (`/crawler-service/crawlers/trend_crawler.py`)
- **1시간 간격 스케줄링**
  - 자동 스케줄링 시스템 구현
- **실시간/1일/주간/월간 데이터 저장**
  - TrendingKeyword 모델로 체계적 관리

### 3.3 크롤링 시스템 기능
- Flask API 서버 (`/crawler-service/app.py`)
- 수동 크롤링 API 엔드포인트
- 크롤링 상태 모니터링
- 로그 관리 시스템
- Docker 환경 설정


## 4. AI 분석 시스템 구현 

### 4.1 뉴스 요약 시스템 
- **AI API 연동**: OpenAI GPT-3.5-turbo 완전 통합
  - 크롤링된 뉴스 자동 요약 (최대 100자) 
  - AI 기반 핵심 주장 추출 
  - "의심 포인트" 자동 분석 

### 4.2 자동 질문 생성 
- **질문 자동 생성**: "이 뉴스 진짜일까요?" 형태 / 보기는 3~4개.
- **찬반 성향 분류**: AI 기반 뉴스 성향 분석 
- **사용자 참여 유도**: 투표 시스템과 연동 준비 완료 

### 4.3 팩트체킹 시스템 연동  
- **신뢰도 점수**: AI 기반 뉴스 신뢰도 평가 (0-100점) 
- **소스 검증**: 언론사 신뢰도 데이터베이스 연동 
- **크로스 체킹**: 복수 언론사 보도 비교 분석 준비 

#### 4.4 AI 분석 프로세스
뉴스 입력 → AI 요약 → 주장 추출 → 의심점 분석 → 질문 생성 → 성향 분석 → 신뢰도 계산

## 5. 사용자 서비스 구현 

### 5.1 관리자 화면 개발 
- **뉴스 수집 모니터링**: 크롤링 상태 실시간 대시보드
- **AI 분석 결과 관리**: 요약, 질문, 신뢰도 관리 시스템
- **팩트체킹 승인**: 관리자 검토 및 승인 워크플로우

### 5.2 사용자 화면 개발 
- **뉴스 피드**: AI 요약된 뉴스 목록 및 상세 페이지
- **팩트체킹 참여**: 질문 투표 및 토론 시스템
- **신뢰도 시각화**: 뉴스별 신뢰도 점수 및 분석 결과 표시

### 5.3 API 서비스 
- **RESTful API**: 뉴스 분석 결과 제공 엔드포인트
- **실시간 업데이트**: WebSocket 기반 실시간 알림
- **사용자 피드백**: 투표 결과 수집 및 분석 시스템


6.1 레이아웃 구성
- Header (공통)
- Contents (메인/서브)
- Footer (공통)
- 반투명 배경

6.2 CSS/JS 파일 구성
- common.css/js (헤더, 푸터, 광고)
- main.css/js (메인화면)
- sub.css/js (서브화면)

6.3 반응형 설계
- 메인: 1280px
- 서브: 1000px
- 모바일: 제목 25px, 본문 15px

7.1 메인 화면 (factlab_main.html) 나머지 파일은 제공.  /Users/yun/Projects/FactLab/user-service/html
- 실시간 이슈 뉴스 (각 메뉴별 1개씩 총 6개)
- 트렌딩 키워드 (실시간/1일/주간/월간)
- 인기 게시판 (1일/주간/월간, 10개)
- 오늘의 뉴스
- 주간/월간 베스트

7.2 광고 영역
- 상단: 1200px × 90px
- 하단: 1200px × 200px
- 좌우: 160px

8.1 뉴스 피드 (factlab_news_feed.html)
- 카테고리별 뉴스 목록
- AI 요약 포함
- 투표 기능 프리뷰

8.2 뉴스 상세 (factlab_news_detail.html)
- 뉴스 원문
- AI 요약
- 투표 시스템
- 댓글 시스템

9.1 게시판 시스템
- 게시글 목록 (factlab_board_list.html)
- 게시글 작성 (factlab_board_write.html)
- 게시글 상세 (factlab_board_detail.html)

9.2 사용자 시스템
- 로그인/회원가입 (factlab_login.html, factlab_register.html)
- 마이페이지 (factlab_mypage.html)
- 설정 (factlab_settings.html)
- 메인에서 추출한 헤더, 푸터는 공통으로 사용.
- CSS파일은 총 3개. main.css(메인 전용), sub.css(뉴스관련), 게시판.css(모든 게시판))
- 

10.1 정기 작업 설정
- 뉴스 수집: 3시간 간격
- 트렌딩 키워드: 1시간 간격
- AI 요약: 실시간 트리거
- 데이터 정리: 30일 후 삭제

10.2 성능 최적화
- 캐싱 시스템
- 데이터베이스 최적화
- CDN 연동

11.1 기능 테스트
- 크롤링 정확성
- AI 요약 품질
- 사용자 인터페이스
- 반응형 디자인

11.2 성능 테스트
- 서버 부하 테스트
- 데이터베이스 성능
- 크롤링 안정성

11.3 배포
- 서버 환경 구축
- 도메인 연결
- SSL 인증서
- 모니터링 시스템




1단계: 기본 환경 설정 및 테스트 (우선순위: 높음)
<input disabled="" type="checkbox"> Docker 환경 테스트: 모든 서비스가 정상적으로 빌드되고 실행되는지 확인
<input disabled="" type="checkbox"> 데이터베이스 연결: PostgreSQL 연결 및 테이블 생성 확인
<input disabled="" type="checkbox"> 기본 라우팅: 각 서비스의 기본 페이지 접근 테스트
<input disabled="" type="checkbox"> 정적 파일 서빙: CSS/JS/이미지 파일 정상 로드 확인
2단계: 공통 모듈 개발 (우선순위: 높음)
<input disabled="" type="checkbox"> 인증 시스템: JWT 토큰 기반 로그인/로그아웃
<input disabled="" type="checkbox"> 사용자 관리: 회원가입, 로그인, 프로필 관리
<input disabled="" type="checkbox"> 데이터베이스 ORM: SQLAlchemy 모델 정의
<input disabled="" type="checkbox"> API 응답 포맷: 표준 JSON 응답 형식 정의
3단계: 크롤러/AI 서비스 개발 (우선순위: 중간)
<input disabled="" type="checkbox"> 뉴스 크롤러: 네이버, 다음 뉴스 RSS 수집
<input disabled="" type="checkbox"> AI 요약: OpenAI API 연동 및 뉴스 요약 생성
<input disabled="" type="checkbox"> 스케줄러: 주기적 뉴스 수집 및 처리
<input disabled="" type="checkbox"> 데이터 저장: 수집된 뉴스 데이터 DB 저장
4단계: 사용자 페이지 개발 (우선순위: 높음)
<input disabled="" type="checkbox"> 메인 페이지: 최신 뉴스 피드 표시
<input disabled="" type="checkbox"> 뉴스 상세: 뉴스 내용 및 AI 요약 표시
<input disabled="" type="checkbox"> 게시판: 카테고리별 토론 게시판
<input disabled="" type="checkbox"> 사용자 인터페이스: 로그인, 회원가입, 마이페이지
5단계: 관리자 페이지 개발 (우선순위: 중간)
<input disabled="" type="checkbox"> 대시보드: 실시간 통계 및 모니터링
<input disabled="" type="checkbox"> 사용자 관리: 사용자 목록, 권한 관리
<input disabled="" type="checkbox"> 콘텐츠 관리: 뉴스 승인, 게시판 관리
<input disabled="" type="checkbox"> 시스템 관리: 로그, 백업, 설정
6단계: 고급 기능 개발 (우선순위: 낮음)
<input disabled="" type="checkbox"> 실시간 알림: WebSocket 기반 알림 시스템
<input disabled="" type="checkbox"> 검색 기능: 뉴스 및 게시글 검색
<input disabled="" type="checkbox"> 추천 시스템: 사용자 관심사 기반 뉴스 추천
<input disabled="" type="checkbox"> 광고 시스템: 수익화 기능


## 관리자 절차
클롤링한 뉴스를 하나의 큐 형식으로 아래와같은 프로세스를 통해 사용자에게 제공.
1. 크롤링으로 뉴스 수집 > 수집한 뉴스는 AI요약관리에 노출됨 (정기 스케줄에 의해 수집)
2. AI뉴스분석에서 관리자가 수집한 뉴스 선택 , [ai분석] 버튼클릭 > 클릭 해야 AI 사용해서 뉴스 분석 > 분석 완료된 뉴스는 '뉴스관리' 메뉴에 노출 (분석되지 않은 뉴스는 나타나지 않음, 분석 이후에는 이 메뉴에서 뉴스 사라짐.)
3. '뉴스관리'에 있는 분석완료된 뉴스는 승인버튼 클릭 / 이때 내용 않맞을 경우 '거부' 후 '재분석' 하거나 뉴스삭제.
4. 승인된 뉴스가 사용자화면 메인, 각 분야별 화면에 노출됨.

5. 크롤링버튼 클릭 시 실제로 크롤링으로 뉴스를 수집해야해. 근데 그런 기능이 없는거 같아. 
그리고. 수동으로 뉴스를 수집하기 위해 크롤링 버튼을 개발했지만, 원래는 배치를 통해서 정기적으로 수집할거야. 
일단 목업데이터 삭제.해봐 내가 크롤링 버튼 눌러서 실제로 뉴스 수집 하는지 테스트할께.

6. ai 분석은 현재 gemini 로 하고 있어. 소스 체크해. 더불어서 open ai 소스는 모두 삭제해.
7. ai 분석 후 db에 저장해.
8. contest 는 뉴스의 내용이어야 하는데 왜 url이 저장되어 있지? 내용은 어디에 저장하지? 확인해